{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce380d11-ca1f-4a71-b181-05f0eed80988",
   "metadata": {},
   "source": [
    "## Installing BERTopic and other necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ce7bc6-4382-4683-9051-07d9ad9cab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/rapids\n",
      "\n",
      "  added / updated specs:\n",
      "    - hdbscan\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.6.15  |       ha878542_0         149 KB  conda-forge\n",
      "    certifi-2022.6.15          |   py39hf3d152e_0         155 KB  conda-forge\n",
      "    hdbscan-0.8.28             |   py39hce5d2b2_1         706 KB  conda-forge\n",
      "    openssl-1.1.1q             |       h166bdaf_0         2.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  hdbscan            conda-forge/linux-64::hdbscan-0.8.28-py39hce5d2b2_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                    2022.5.18.1-ha878542_0 --> 2022.6.15-ha878542_0\n",
      "  certifi                        2022.5.18.1-py39hf3d152e_0 --> 2022.6.15-py39hf3d152e_0\n",
      "  openssl                                 1.1.1o-h166bdaf_0 --> 1.1.1q-h166bdaf_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "hdbscan-0.8.28       | 706 KB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 149 KB    | ##################################### | 100% \n",
      "openssl-1.1.1q       | 2.1 MB    | ##################################### | 100% \n",
      "certifi-2022.6.15    | 155 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge hdbscan -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472bbb0c-b542-41ab-adee-d94f29c0f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/envs/rapids/lib/python3.9/site-packages (22.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: hdbscan in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.8.28)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.37.1)\n",
      "Requirement already satisfied: cython>=0.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (0.29.30)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (0.24.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (1.21.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.1.2\n",
      "    Uninstalling pip-22.1.2:\n",
      "      Successfully uninstalled pip-22.1.2\n",
      "Successfully installed pip-22.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip hdbscan wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6cbc8d-55b0-4c25-8cd2-ee7411fdd978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.11.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers>=0.4.1\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: umap-learn>=0.5.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (0.5.3)\n",
      "Collecting plotly>=4.7.0\n",
      "  Downloading plotly-5.9.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (1.21.6)\n",
      "Requirement already satisfied: hdbscan>=0.8.28 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (0.8.28)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (0.24.2)\n",
      "Collecting pyyaml<6.0\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (4.64.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.6.0)\n",
      "Requirement already satisfied: cython>=0.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (0.29.30)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.6.0\n",
      "  Downloading torch-1.12.1-cp39-cp39-manylinux1_x86_64.whl (776.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.4/776.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp39-cp39-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.49 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.7)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (60.10.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.1/765.1 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/envs/rapids/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.6.15)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125940 sha256=c1ed8b783c6ba7817a9eed85bd76f71c3b66c8f7f5af7f70892971fcb9b5ea81\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, tenacity, regex, pyyaml, filelock, torchvision, plotly, nltk, huggingface-hub, transformers, sentence-transformers, bertopic\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 22.6.0 requires cupy-cuda115, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bertopic-0.11.0 filelock-3.8.0 huggingface-hub-0.8.1 nltk-3.7 plotly-5.9.0 pyyaml-5.4.1 regex-2022.7.25 sentence-transformers-2.2.2 sentencepiece-0.1.97 tenacity-8.0.1 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.21.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bertopic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feefffe0-1b77-48e7-8d03-1b6d5377ad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.24.49-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting botocore<1.28.0,>=1.27.49\n",
      "  Downloading botocore-1.27.49-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from boto3) (1.0.0)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m705.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.49->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.49->boto3) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.49->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.21\n",
      "    Uninstalling botocore-1.24.21:\n",
      "      Successfully uninstalled botocore-1.24.21\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.3.3 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.49 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.24.49 botocore-1.27.49 s3transfer-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access folders\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc56072b-c3b7-47c9-add2-16deceab4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awswrangler\n",
      "  Downloading awswrangler-2.16.1-py3-none-any.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backoff<3.0.0,>=1.11.1\n",
      "  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.4.2)\n",
      "Collecting pymysql<2.0.0,>=1.0.0\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gremlinpython<4.0.0,>=3.5.2\n",
      "  Downloading gremlinpython-3.6.1-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.21.6)\n",
      "Collecting openpyxl<3.1.0,>=3.0.0\n",
      "  Downloading openpyxl-3.0.10-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow<7.1.0,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (7.0.0)\n",
      "Collecting progressbar2<5.0.0,>=4.0.0\n",
      "  Downloading progressbar2-4.0.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting requests-aws4auth<2.0.0,>=1.1.1\n",
      "  Downloading requests_aws4auth-1.1.2-py2.py3-none-any.whl (24 kB)\n",
      "Collecting redshift-connector<2.1.0,>=2.0.889\n",
      "  Downloading redshift_connector-2.0.908-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.0/112.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: botocore<2.0.0,>=1.23.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.27.49)\n",
      "Collecting opensearch-py<2.0.0,>=1.0.0\n",
      "  Downloading opensearch_py-1.1.0-py2.py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpath-ng<2.0.0,>=1.5.3\n",
      "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
      "Collecting pg8000<2.0.0,>=1.20.0\n",
      "  Downloading pg8000-1.29.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.24.49)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (1.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: aiohttp<=3.8.1,>=3.8.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (3.8.1)\n",
      "Collecting aenum<4.0.0,>=1.4.5\n",
      "  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.5.5)\n",
      "Collecting isodate<1.0.0,>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /opt/conda/envs/rapids/lib/python3.9/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (5.1.1)\n",
      "Collecting ply\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.9/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (1.16.0)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/rapids/lib/python3.9/site-packages (from opensearch-py<2.0.0,>=1.0.0->awswrangler) (2022.6.15)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas<2.0.0,>=1.2.0->awswrangler) (2022.1)\n",
      "Collecting scramp>=1.4.1\n",
      "  Downloading scramp-1.4.1-py3-none-any.whl (8.5 kB)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Downloading python_utils-3.3.3-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.11.1)\n",
      "Requirement already satisfied: requests<2.28.1,>=2.23.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.27.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.9/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (21.3)\n",
      "Collecting lxml>=4.6.5\n",
      "  Downloading lxml-4.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (2.0.12)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.7.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<2.28.1,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.3)\n",
      "Collecting asn1crypto>=1.4.0\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.0.9)\n",
      "Installing collected packages: ply, asn1crypto, aenum, scramp, python-utils, pymysql, opensearch-py, lxml, jsonpath-ng, isodate, et-xmlfile, backoff, requests-aws4auth, progressbar2, pg8000, openpyxl, gremlinpython, redshift-connector, awswrangler\n",
      "Successfully installed aenum-3.1.11 asn1crypto-1.5.1 awswrangler-2.16.1 backoff-2.1.2 et-xmlfile-1.1.0 gremlinpython-3.6.1 isodate-0.6.1 jsonpath-ng-1.5.3 lxml-4.9.1 openpyxl-3.0.10 opensearch-py-1.1.0 pg8000-1.29.1 ply-3.11 progressbar2-4.0.0 pymysql-1.0.2 python-utils-3.3.3 redshift-connector-2.0.908 requests-aws4auth-1.1.2 scramp-1.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access Amazon S3 buckets\n",
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26cf1055-8e61-48f0-8486-b8bc21214054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache_beam\n",
      "  Downloading apache_beam-2.40.0-cp39-cp39-manylinux2010_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mwparserfromhell\n",
      "  Downloading mwparserfromhell-0.6.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle<3,>=2.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2.1.0)\n",
      "Collecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (4.2.0)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (7.0.0)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (1.21.6)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2.8.2)\n",
      "Collecting httplib2<0.21.0,>=0.8\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2.27.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (1.5.0)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (3.20.1)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting grpcio<2,>=1.33.1\n",
      "  Downloading grpcio-1.47.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2022.1)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.3/516.3 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson<4.0\n",
      "  Downloading orjson-3.7.11-cp39-cp39-manylinux_2_28_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from grpcio<2,>=1.33.1->apache_beam) (1.16.0)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from httplib2<0.21.0,>=0.8->apache_beam) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.3)\n",
      "Building wheels for collected packages: crcmod, dill, docopt\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-py3-none-any.whl size=18848 sha256=940a8d4e791dfd864ad7014cbcf814b3119b553128d81ce63069b07ac97d2ad6\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=88099ea403d37ad38c00769418cfffffb75f41b22d03bea4a00fe7b9e503a553\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/0b/ce/75d96dd714b15e51cb66db631183ea3844e0c4a6d19741a149\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=c33f775f3c84f632f4e8a51288b1cb776eba31a88a1a2997517b77af3a739222\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built crcmod dill docopt\n",
      "Installing collected packages: docopt, crcmod, pymongo, pydot, proto-plus, orjson, mwparserfromhell, httplib2, grpcio, dill, hdfs, apache_beam\n",
      "Successfully installed apache_beam-2.40.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 grpcio-1.47.0 hdfs-2.7.0 httplib2-0.20.4 mwparserfromhell-0.6.4 orjson-3.7.11 proto-plus-1.22.0 pydot-1.4.2 pymongo-3.12.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access Wikipedia corpus\n",
    "!pip install apache_beam mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cba1053f-1605-4109-abb6-d47fb0aac4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (0.3.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (2022.5.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.1.1\n",
      "    Uninstalling dill-0.3.1.1:\n",
      "      Successfully uninstalled dill-0.3.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 multiprocess-0.70.13 responses-0.18.0 xxhash-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access Wikipedia corpus\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fa566-80da-435d-b8e5-81a821ae3d72",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2809c2f-66e6-4220-a7a0-b184b2819bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import rmm\n",
    "import os\n",
    "import boto3\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "import numpy as np\n",
    "import time\n",
    "pd.set_option('max_colwidth', -1)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "rmm.reinitialize(pool_allocator=True,initial_pool_size=5e+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203cff40-a763-4b61-a123-2b130da5afbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/CUADv1.json', 'data/an4_sphere.tar.gz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data from S3 bucket\n",
    "s3_client = boto3.client('s3')\n",
    "s3_bucket_name = 'nvidia-rapids'\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket=s3.Bucket(s3_bucket_name)\n",
    "bucket_list = []\n",
    "for file in my_bucket.objects.filter():\n",
    "    file_name=file.key\n",
    "    if file_name!=\"data/\" and file_name.find(\"data/\")!=-1:\n",
    "        bucket_list.append(file.key)\n",
    "bucket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89449a2-a612-4405-9e8a-691efa1a185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb55adb901444caae8fa25fc2033bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/11.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c00b96b98b4e9b83aec583131cd8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/7.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikipedia/20220301.en (download: 19.18 GiB, generated: 18.88 GiB, post-processed: Unknown size, total: 38.07 GiB) to /root/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70047d961bf46feb84aa5b7a3fd38c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222fed63556645f4a1646b89dbdccba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikipedia downloaded and prepared to /root/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8e4d11478e42c8957cda4971484afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['data/CUADv1.json', 'data/an4_sphere.tar.gz', 'docs', 'data_wiki']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing custom datasets for the lab\n",
    "\n",
    "#Importing news dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "docs = fetch_20newsgroups(subset='all')['data']\n",
    "bucket_list.append('docs')\n",
    "\n",
    "#Importing Wikidata corpus\n",
    "from datasets import load_dataset\n",
    "data_wiki = pd.DataFrame(load_dataset(\"wikipedia\", \"20220301.en\"))\n",
    "bucket_list.append('data_wiki')\n",
    "\n",
    "bucket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ce4a2a-9a49-4518-a4b5-8123d4effc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    if bucket_list[i].find(\".json\")!=-1:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_json('s3://'+s3_bucket_name+'/'+bucket_list[i], orient='columns')\n",
    "    elif bucket_list[i].find(\".tar.gz\")!=-1:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_csv('s3://'+s3_bucket_name+'/'+bucket_list[i], compression='gzip', header=None, encoding=\"cp437\", delimiter =';', engine='python', on_bad_lines='skip')\n",
    "        # globals()[\"data_\" + str(i)] = pd.read_csv('s3://'+s3_bucket_name+'/'+bucket_list[i], compression='gzip', header=0, sep=' ', on_bad_lines='skip')\n",
    "    elif bucket_list[i].find(\".pkl\")!=-1:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_pickle('s3://'+s3_bucket_name+'/'+bucket_list[i])\n",
    "    elif bucket_list[i]=='docs':\n",
    "        globals()[\"data_\" + str(i)] = docs\n",
    "    elif bucket_list[i]=='data_wiki':\n",
    "        globals()[\"data_\" + str(i)] = data_wiki\n",
    "    else:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_csv('s3://'+s3_bucket_name+'/'+bucket_list[i])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62a59486-feea-4944-8f35-b66417a25529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to vectorize dataset 1(in s): 0.9\n",
      "Time to vectorize dataset 2(in s): 0.03\n",
      "Time to vectorize dataset 4(in s): 7.31\n"
     ]
    }
   ],
   "source": [
    "#Text cleaning before fitting into model\n",
    "def random_function(x):\n",
    "    return ((str(x).replace(r\"[^a-zA-Z ]+\", \" \")).strip())\n",
    "# data_0 = data_0.data.apply(str).str.replace(r\"[^a-zA-Z ]+\", \" \").str.strip()\n",
    "# data_3=data_3['train'].astype(str).str.replace(r\"[^a-zA-Z ]+\", \" \").str.strip()\n",
    "\n",
    "start_time = time.time()\n",
    "data_0 = np.vectorize(random_function)(data_0.data) \n",
    "end_time = time.time() - start_time\n",
    "print(\"Time to vectorize dataset 1(in s): \"+ str(np.round(end_time, decimals=2)))\n",
    "\n",
    "start_time = time.time()\n",
    "data_1 = np.vectorize(random_function)(data_1[0].head(20000))\n",
    "end_time = time.time() - start_time\n",
    "print(\"Time to vectorize dataset 2(in s): \"+ str(np.round(end_time, decimals=2)))\n",
    "\n",
    "start_time = time.time()\n",
    "data_3=data_3.head(10000)\n",
    "data_3 = np.vectorize(random_function)(data_3.train)\n",
    "end_time = time.time() - start_time\n",
    "print(\"Time to vectorize dataset 4(in s): \"+ str(np.round(end_time, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb13deb4-f139-4f0e-a04e-7132fb6d1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from cuml.cluster import HDBSCAN as HDBSCAN_gpu\n",
    "from cuml.manifold import UMAP as UMAP_gpu\n",
    "from cuml.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786d4910-cc16-44e1-8847-95ef19f4f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to perform topic modeling for dataset1(in s): 20.41\n",
      "Time to perform topic modeling for dataset2(in s): 7.7\n",
      "Time to perform topic modeling for dataset3(in s): 36.32\n",
      "Time to perform topic modeling for dataset4(in s): 138.91\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    globals()[\"start_time_\" + str(i)] = time.time()\n",
    "    globals()[\"umap_model_\" + str(i)] = UMAP_gpu(n_components=5, n_neighbors=15, min_dist=0.0)\n",
    "    globals()[\"hdbscan_model_\" + str(i)] = HDBSCAN_gpu(min_samples=10, gen_min_span_tree=True)\n",
    "    # Pass the above models to be used in BERTopic\n",
    "    globals()[\"topic_model_cubert_\" + str(i)] = BERTopic(umap_model=globals()[\"umap_model_\" + str(i)], hdbscan_model=globals()[\"hdbscan_model_\" + str(i)])\n",
    "    globals()[\"topics_\" + str(i)], globals()[\"probs_\" + str(i)] = globals()[\"topic_model_cubert_\" + str(i)].fit_transform(globals()[\"data_\" + str(i)])\n",
    "    globals()[\"end_time_\" + str(i)] = time.time() - globals()[\"start_time_\" + str(i)]\n",
    "    print(\"Time to perform topic modeling for dataset\" +str(i+1) + \"(in s): \"+ str(np.round(globals()[\"end_time_\" + str(i)], decimals=2)))\n",
    "    \n",
    "    viz_topics = globals()[\"topic_model_cubert_\" + str(i)].visualize_topics()\n",
    "    # print(viz_topics.show())\n",
    "    viz_topics.write_html(\"viz_topics_cu_\"+str(i)+\".html\")\n",
    "    viz_barchart = globals()[\"topic_model_cubert_\" + str(i)].visualize_barchart()\n",
    "    # print(viz_barchart.show())\n",
    "    viz_barchart.write_html(\"viz_barchart_cu_\"+str(i)+\".html\")\n",
    "    # viz_docs = globals()[\"topic_model_cubert_\" + str(i)].visualize_documents(globals()[\"data_\" + str(i)])\n",
    "    # viz_docs.write_html(\"viz_docs_\"+str(i)+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3517e44f-442a-4443-bad6-c0423ad18b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3835</td>\n",
       "      <td>-1_the_of_in_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0_american_politician_english_author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>1_function_is_numbers_if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>2_species_are_have_prey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>161</td>\n",
       "      <td>3_album_band_music_rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "      <td>203_disk_disc_drive_1541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>204_axon_csf_axons_myelin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "      <td>205_adelaide_governorgeneral_australian_australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>206_hopkins_orton_hopkinss_lear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>207_history_historiography_historical_historians</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name\n",
       "0   -1      3835   -1_the_of_in_to                                  \n",
       "1    0      254    0_american_politician_english_author             \n",
       "2    1      202    1_function_is_numbers_if                         \n",
       "3    2      176    2_species_are_have_prey                          \n",
       "4    3      161    3_album_band_music_rock                          \n",
       "..  ..      ...                        ...                          \n",
       "204  203    5      203_disk_disc_drive_1541                         \n",
       "205  204    5      204_axon_csf_axons_myelin                        \n",
       "206  205    5      205_adelaide_governorgeneral_australian_australia\n",
       "207  206    5      206_hopkins_orton_hopkinss_lear                  \n",
       "208  207    5      207_history_historiography_historical_historians \n",
       "\n",
       "[209 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_cubert_0.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c69e9a24-fea9-4aa8-8f39-d1c5c2f98fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('american', 0.036497663984866646),\n",
       " ('politician', 0.024232471732520897),\n",
       " ('english', 0.017947174973273316),\n",
       " ('author', 0.015749438133573622),\n",
       " ('player', 0.014422789762665873),\n",
       " ('actor', 0.014185589195761851),\n",
       " ('singersongwriter', 0.011789128358347134),\n",
       " ('academic', 0.011492077679810878),\n",
       " ('lawyer', 0.01041322482576432),\n",
       " ('actress', 0.010152941090100343)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_cubert_0.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae5685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_cubert_1.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_cubert_1.get_topic(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d725acb-2fcc-43f6-a176-c5e0da29e987",
   "metadata": {},
   "source": [
    "## Appendix - Running with CUDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f731fa2d-de23-4d83-8609-f6b83a6a37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from cuml.cluster import HDBSCAN as HDBSCAN_gpu\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f7f30d7-4a33-440a-978d-f854547bb1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 4.04 s, total: 1min 20s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create instances of GPU-accelerated UMAP and HDBSCAN\n",
    "umap_model_3 = UMAP(n_components=5, n_neighbors=15, min_dist=0.0)\n",
    "hdbscan_model_3 = HDBSCAN_gpu(min_samples=10, gen_min_span_tree=True)\n",
    "\n",
    "# Pass the above models to be used in BERTopic\n",
    "topic_model_3 = BERTopic(umap_model=umap_model_3, hdbscan_model=hdbscan_model_3)\n",
    "topics_gpu_3, probs_gpu_3 = topic_model_3.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa109136-9415-4782-bef0-a2f6c517261d",
   "metadata": {},
   "source": [
    "### Running customized CuBERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0434cb5b-bdc4-4162-8b8a-f734e3fb9ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03ba07-dc0d-4788-bc45-964494e78ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Customizing embedding \n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
    "embeddings = normalize(embeddings)\n",
    "\n",
    "# Create instances of GPU-accelerated UMAP and HDBSCAN\n",
    "umap_model_4 = UMAP(n_components=5, n_neighbors=15, min_dist=0.0)\n",
    "hdbscan_model_4 = HDBSCAN_gpu(min_samples=10, gen_min_span_tree=True)\n",
    "\n",
    "# Pass the above models to be used in BERTopic\n",
    "topic_model_4 = BERTopic(umap_model=umap_model_4, hdbscan_model=hdbscan_model_4)\n",
    "topics_gpu_4, probs_gpu_4 = topic_model_4.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb62f39-4b05-4e04-9bbd-cd24c09e971a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
