{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce380d11-ca1f-4a71-b181-05f0eed80988",
   "metadata": {},
   "source": [
    "## Installing BERTopic and other necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ce7bc6-4382-4683-9051-07d9ad9cab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.12.0\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/rapids\n",
      "\n",
      "  added / updated specs:\n",
      "    - hdbscan\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.6.15  |       ha878542_0         149 KB  conda-forge\n",
      "    certifi-2022.6.15          |   py39hf3d152e_0         155 KB  conda-forge\n",
      "    hdbscan-0.8.28             |   py39hce5d2b2_1         706 KB  conda-forge\n",
      "    openssl-1.1.1q             |       h166bdaf_0         2.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  hdbscan            conda-forge/linux-64::hdbscan-0.8.28-py39hce5d2b2_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                    2022.5.18.1-ha878542_0 --> 2022.6.15-ha878542_0\n",
      "  certifi                        2022.5.18.1-py39hf3d152e_0 --> 2022.6.15-py39hf3d152e_0\n",
      "  openssl                                 1.1.1o-h166bdaf_0 --> 1.1.1q-h166bdaf_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1q       | 2.1 MB    | ##################################### | 100% \n",
      "hdbscan-0.8.28       | 706 KB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 149 KB    | ##################################### | 100% \n",
      "certifi-2022.6.15    | 155 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge hdbscan -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472bbb0c-b542-41ab-adee-d94f29c0f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/envs/rapids/lib/python3.9/site-packages (22.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: hdbscan in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.8.28)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/rapids/lib/python3.9/site-packages (0.37.1)\n",
      "Requirement already satisfied: cython>=0.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (0.29.30)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (1.21.6)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.1.2\n",
      "    Uninstalling pip-22.1.2:\n",
      "      Successfully uninstalled pip-22.1.2\n",
      "Successfully installed pip-22.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip hdbscan wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6cbc8d-55b0-4c25-8cd2-ee7411fdd978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Downloading bertopic-0.11.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml<6.0\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting plotly>=4.7.0\n",
      "  Downloading plotly-5.9.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (0.24.2)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (0.5.3)\n",
      "Collecting sentence-transformers>=0.4.1\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: hdbscan>=0.8.28 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (0.8.28)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (4.64.0)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from bertopic) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.6.0)\n",
      "Requirement already satisfied: cython>=0.27 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (0.29.30)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from hdbscan>=0.8.28->bertopic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas>=1.1.5->bertopic) (2022.1)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.6.0\n",
      "  Downloading torch-1.12.1-cp39-cp39-manylinux1_x86_64.whl (776.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.4/776.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp39-cp39-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numba>=0.49 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.55.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.7)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.27.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (60.10.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.38.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (765 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.1/765.1 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/conda/envs/rapids/lib/python3.9/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.12)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125940 sha256=9ae8dc1b86b8a543e4c27e46d2a3e98a4cdadd5a73321769e28416db262f022d\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, tenacity, regex, pyyaml, filelock, torchvision, plotly, nltk, huggingface-hub, transformers, sentence-transformers, bertopic\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 22.6.0 requires cupy-cuda115, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bertopic-0.11.0 filelock-3.8.0 huggingface-hub-0.8.1 nltk-3.7 plotly-5.9.0 pyyaml-5.4.1 regex-2022.7.25 sentence-transformers-2.2.2 sentencepiece-0.1.97 tenacity-8.0.1 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.21.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bertopic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feefffe0-1b77-48e7-8d03-1b6d5377ad8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.24.49-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.5/132.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from boto3) (1.0.0)\n",
      "Collecting botocore<1.28.0,>=1.27.49\n",
      "  Downloading botocore-1.27.49-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.49->boto3) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.49->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.49->boto3) (1.16.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.21\n",
      "    Uninstalling botocore-1.24.21:\n",
      "      Successfully uninstalled botocore-1.24.21\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.3.3 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.49 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.24.49 botocore-1.27.49 s3transfer-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access folders\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc56072b-c3b7-47c9-add2-16deceab4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awswrangler\n",
      "  Downloading awswrangler-2.16.1-py3-none-any.whl (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gremlinpython<4.0.0,>=3.5.2\n",
      "  Downloading gremlinpython-3.6.1-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m925.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow<7.1.0,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (7.0.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.24.49)\n",
      "Collecting jsonpath-ng<2.0.0,>=1.5.3\n",
      "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
      "Collecting redshift-connector<2.1.0,>=2.0.889\n",
      "  Downloading redshift_connector-2.0.908-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.0/112.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-aws4auth<2.0.0,>=1.1.1\n",
      "  Downloading requests_aws4auth-1.1.2-py2.py3-none-any.whl (24 kB)\n",
      "Collecting openpyxl<3.1.0,>=3.0.0\n",
      "  Downloading openpyxl-3.0.10-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.21.6)\n",
      "Collecting backoff<3.0.0,>=1.11.1\n",
      "  Downloading backoff-2.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting progressbar2<5.0.0,>=4.0.0\n",
      "  Downloading progressbar2-4.0.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting pymysql<2.0.0,>=1.0.0\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.4.2)\n",
      "Collecting opensearch-py<2.0.0,>=1.0.0\n",
      "  Downloading opensearch_py-1.1.0-py2.py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pg8000<2.0.0,>=1.20.0\n",
      "  Downloading pg8000-1.29.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from awswrangler) (1.27.49)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from boto3<2.0.0,>=1.20.17->awswrangler) (0.6.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (1.26.9)\n",
      "Collecting isodate<1.0.0,>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.5.5)\n",
      "Requirement already satisfied: aiohttp<=3.8.1,>=3.8.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (3.8.1)\n",
      "Collecting aenum<4.0.0,>=1.4.5\n",
      "  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.9/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (1.16.0)\n",
      "Collecting ply\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator in /opt/conda/envs/rapids/lib/python3.9/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (5.1.1)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/rapids/lib/python3.9/site-packages (from opensearch-py<2.0.0,>=1.0.0->awswrangler) (2022.6.15)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas<2.0.0,>=1.2.0->awswrangler) (2022.1)\n",
      "Collecting scramp>=1.4.1\n",
      "  Downloading scramp-1.4.1-py3-none-any.whl (8.5 kB)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Downloading python_utils-3.3.3-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.11.1)\n",
      "Requirement already satisfied: requests<2.28.1,>=2.23.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.27.1)\n",
      "Collecting lxml>=4.6.5\n",
      "  Downloading lxml-4.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.9/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (2.0.12)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (21.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<2.28.1,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.3)\n",
      "Collecting asn1crypto>=1.4.0\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.0.9)\n",
      "Installing collected packages: ply, asn1crypto, aenum, scramp, python-utils, pymysql, opensearch-py, lxml, jsonpath-ng, isodate, et-xmlfile, backoff, requests-aws4auth, progressbar2, pg8000, openpyxl, gremlinpython, redshift-connector, awswrangler\n",
      "Successfully installed aenum-3.1.11 asn1crypto-1.5.1 awswrangler-2.16.1 backoff-2.1.2 et-xmlfile-1.1.0 gremlinpython-3.6.1 isodate-0.6.1 jsonpath-ng-1.5.3 lxml-4.9.1 openpyxl-3.0.10 opensearch-py-1.1.0 pg8000-1.29.1 ply-3.11 progressbar2-4.0.0 pymysql-1.0.2 python-utils-3.3.3 redshift-connector-2.0.908 requests-aws4auth-1.1.2 scramp-1.4.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access Amazon S3 buckets\n",
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cf1055-8e61-48f0-8486-b8bc21214054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apache_beam\n",
      "  Downloading apache_beam-2.40.0-cp39-cp39-manylinux2010_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mwparserfromhell\n",
      "  Downloading mwparserfromhell-0.6.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (516 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m516.3/516.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (1.5.0)\n",
      "Collecting grpcio<2,>=1.33.1\n",
      "  Downloading grpcio-1.47.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (4.2.0)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.7.11-cp39-cp39-manylinux_2_28_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httplib2<0.21.0,>=0.8\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2022.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2.1.0)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (7.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (2.8.2)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (3.20.1)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.14.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from apache_beam) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from grpcio<2,>=1.33.1->apache_beam) (1.16.0)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from httplib2<0.21.0,>=0.8->apache_beam) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2022.6.15)\n",
      "Building wheels for collected packages: crcmod, dill, docopt\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-py3-none-any.whl size=18848 sha256=03d6fcc57d0d161446aa4d8eb9979526c634385b25e9c887bb2bbb246462594b\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=cc7e1122ae73f53457dc1f9a78c0f980922fa9674d45fa4bac1639773ffdce76\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/0b/ce/75d96dd714b15e51cb66db631183ea3844e0c4a6d19741a149\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=98e35541c8ae4ee7c4b14ea3a41395f8d4fc3c509ff7641fdfb900a110057473\n",
      "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built crcmod dill docopt\n",
      "Installing collected packages: docopt, crcmod, pymongo, pydot, proto-plus, orjson, mwparserfromhell, httplib2, grpcio, dill, hdfs, apache_beam\n",
      "Successfully installed apache_beam-2.40.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 grpcio-1.47.0 hdfs-2.7.0 httplib2-0.20.4 mwparserfromhell-0.6.4 orjson-3.7.11 proto-plus-1.22.0 pydot-1.4.2 pymongo-3.12.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access Wikipedia corpus\n",
    "!pip install apache_beam mwparserfromhell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba1053f-1605-4109-abb6-d47fb0aac4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (0.3.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (1.4.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (4.64.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (21.3)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/rapids/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.1.1\n",
      "    Uninstalling dill-0.3.1.1:\n",
      "      Successfully uninstalled dill-0.3.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 multiprocess-0.70.13 responses-0.18.0 xxhash-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Needed to access Wikipedia corpus\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fa566-80da-435d-b8e5-81a821ae3d72",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2809c2f-66e6-4220-a7a0-b184b2819bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import rmm\n",
    "import os\n",
    "import boto3\n",
    "import sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "import numpy as np\n",
    "import time\n",
    "pd.set_option('max_colwidth', -1)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "rmm.reinitialize(pool_allocator=True,initial_pool_size=5e+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b89449a2-a612-4405-9e8a-691efa1a185c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f0de57aba1433eb17ea7b4ef42322e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/11.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185d7da721aa40d39066439284505a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/7.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikipedia/20220301.en (download: 19.18 GiB, generated: 18.88 GiB, post-processed: Unknown size, total: 38.07 GiB) to /root/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03378a5db8de481b8b1746e78702f89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/15.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18260ee231f4b3c8214da644b8f6c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikipedia downloaded and prepared to /root/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e292a6713a6841eba4a4a5ed6abeaae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['data/CUADv1.json', 'data/an4_sphere.tar.gz', 'docs', 'data_wiki']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing custom datasets for the lab\n",
    "bucket_list = []\n",
    "\n",
    "#Importing news dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "docs = fetch_20newsgroups(subset='all')['data']\n",
    "bucket_list.append('docs')\n",
    "\n",
    "#Importing Wikidata corpus\n",
    "from datasets import load_dataset\n",
    "data_wiki = pd.DataFrame(load_dataset(\"wikipedia\", \"20220301.en\"))\n",
    "bucket_list.append('data_wiki')\n",
    "\n",
    "bucket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data from S3 bucket\n",
    "# s3_client = boto3.client('s3')\n",
    "# s3_bucket_name = 'nvidia-rapids'\n",
    "# s3 = boto3.resource('s3')\n",
    "# my_bucket=s3.Bucket(s3_bucket_name)\n",
    "\n",
    "# for file in my_bucket.objects.filter():\n",
    "#     file_name=file.key\n",
    "#     if file_name!=\"data/\" and file_name.find(\"data/\")!=-1:\n",
    "#         bucket_list.append(file.key)\n",
    "# bucket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ce4a2a-9a49-4518-a4b5-8123d4effc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    if bucket_list[i].find(\".json\")!=-1:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_json('s3://'+s3_bucket_name+'/'+bucket_list[i], orient='columns')\n",
    "    elif bucket_list[i].find(\".tar.gz\")!=-1:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_csv('s3://'+s3_bucket_name+'/'+bucket_list[i], compression='gzip', header=None, encoding=\"cp437\", delimiter =';', engine='python', on_bad_lines='skip')\n",
    "        # globals()[\"data_\" + str(i)] = pd.read_csv('s3://'+s3_bucket_name+'/'+bucket_list[i], compression='gzip', header=0, sep=' ', on_bad_lines='skip')\n",
    "    elif bucket_list[i].find(\".pkl\")!=-1:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_pickle('s3://'+s3_bucket_name+'/'+bucket_list[i])\n",
    "    elif bucket_list[i]=='docs':\n",
    "        globals()[\"data_\" + str(i)] = docs\n",
    "    elif bucket_list[i]=='data_wiki':\n",
    "        globals()[\"data_\" + str(i)] = data_wiki\n",
    "    else:\n",
    "        globals()[\"data_\" + str(i)] = pd.read_csv('s3://'+s3_bucket_name+'/'+bucket_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a59486-feea-4944-8f35-b66417a25529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to vectorize dataset 1(in s): 0.9\n",
      "Time to vectorize dataset 2(in s): 0.03\n",
      "Time to vectorize dataset 4(in s): 7.38\n"
     ]
    }
   ],
   "source": [
    "#Text cleaning before fitting into model\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "pat1=re.compile(r\"[^a-zA-Z ]+\")\n",
    "pat2=re.compile(r'\\b(?:{})\\b'.format('|'.join(stop)))\n",
    "\n",
    "start_time = time.time()\n",
    "data_0 = pd.DataFrame(data_0)\n",
    "data_0.columns = ['train']\n",
    "data_0 = data_0.train.astype(str).str.replace(pat1,\" \").str.replace(pat2,\" \").str.strip()\n",
    "end_time = time.time() - start_time\n",
    "print(\"Time to vectorize dataset 1(in s): \"+ str(np.round(end_time, decimals=2)))\n",
    "\n",
    "start_time = time.time()\n",
    "data_1 = data_1.train.astype(str).str.replace(pat1,\" \").str.replace(pat2,\" \").str.strip()\n",
    "end_time = time.time() - start_time\n",
    "print(\"Time to vectorize dataset 2(in s): \"+ str(np.round(end_time, decimals=2)))\n",
    "\n",
    "# start_time = time.time()\n",
    "# data_2 = data_2.data.astype(str).str.replace(pat1,\" \").str.replace(pat2,\" \").str.strip()\n",
    "# end_time = time.time() - start_time\n",
    "# print(\"Time to vectorize dataset 3(in s): \"+ str(np.round(end_time, decimals=2)))\n",
    "\n",
    "# start_time = time.time()\n",
    "# data_3 = data_3[0].astype(str).str.replace(pat1,\" \").str.replace(pat2,\" \").str.strip()\n",
    "# end_time = time.time() - start_time\n",
    "# print(\"Time to vectorize dataset 4(in s): \"+ str(np.round(end_time, decimals=2)))\n",
    "\n",
    "# def random_function(x):\n",
    "#     return ((str(x).replace(r\"[^a-zA-Z ]+\", \" \")).strip())\n",
    "# data_0 = np.vectorize(random_function)(data_0.data) \n",
    "# data_1 = np.vectorize(random_function)(data_1[0].head(20000))\n",
    "# data_3=data_3.head(10000)\n",
    "# data_0 = data_0.data.apply(str).str.replace(r\"[^a-zA-Z ]+\", \" \").str.strip()\n",
    "# data_3=data_3['train'].astype(str).str.replace(r\"[^a-zA-Z ]+\", \" \").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    print(\"/n Dataset\"+str(i+1)+\" Info-/n\")\n",
    "    print(globals()[\"data_\" + str(i)].info())\n",
    "    print(\"Size: /n\"+str(sys.getsizeof(globals()[\"data_\" + str(i)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786d4910-cc16-44e1-8847-95ef19f4f518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8520174694274cb7a247ff802d113a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cf6f58c6674106b0efb9ee04e51511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faecbfab3cc8476dad615608de3b90b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f189d38064b04b5dbac8f1d73b5a3c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b323525e8e4f269412cbc3a1c28c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dbb354865b42178b64bec870c1d75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa27a8736e834280926dde10b5614f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323ac1d83a7040a596ffcb5525300a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6cfd0875d0404098e9d8369c9557e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1342a451c9b14b45973d61ca44488c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c552bd39a8418e89d528178257e00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e8717f82c443ca9a79c7a1b5b1f825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd41bc30e6442b795d82a2f4e9a8606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3786b618d5cb44b0bdb8e28e40aaf604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to perform topic modeling for dataset1(in s): 37.95\n",
      "Time to perform topic modeling for dataset2(in s): 58.01\n",
      "Time to perform topic modeling for dataset3(in s): 51.84\n",
      "Time to perform topic modeling for dataset4(in s): 154.9\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    globals()[\"start_time_\" + str(i)] = time.time()\n",
    "    globals()[\"topic_model_gpu_\" + str(i)] = BERTopic()\n",
    "    globals()[\"topics_\" + str(i)], globals()[\"probs_\" + str(i)] = globals()[\"topic_model_gpu_\" + str(i)].fit_transform(globals()[\"data_\" + str(i)])\n",
    "    globals()[\"end_time_\" + str(i)] = time.time() - globals()[\"start_time_\" + str(i)]\n",
    "    print(\"Time to perform topic modeling for dataset\" +str(i+1) + \"(in s): \"+ str(np.round(globals()[\"end_time_\" + str(i)], decimals=2)))\n",
    "    \n",
    "    viz_topics = globals()[\"topic_model_gpu_\" + str(i)].visualize_topics()\n",
    "    # print(viz_topics.show())\n",
    "    viz_topics.write_html(\"viz_topics_\"+str(i)+\".html\")\n",
    "    viz_barchart = globals()[\"topic_model_gpu_\" + str(i)].visualize_barchart()\n",
    "    # print(viz_barchart.show())\n",
    "    viz_barchart.write_html(\"viz_barchart_\"+str(i)+\".html\")\n",
    "    viz_docs = globals()[\"topic_model_gpu_\" + str(i)].visualize_documents(globals()[\"data_\" + str(i)])\n",
    "    viz_docs.write_html(\"viz_docs_\"+str(i)+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3517e44f-442a-4443-bad6-c0423ad18b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>2905</td>\n",
       "      <td>-1_the_of_to_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0_american_politician_english_author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>229</td>\n",
       "      <td>1_film_he_his_films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>2_cells_dna_cell_acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>3_species_are_have_their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>193</td>\n",
       "      <td>10</td>\n",
       "      <td>193_french_lit_france_fries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>194</td>\n",
       "      <td>10</td>\n",
       "      <td>194_nietzsche_wittgenstein_marx_hegel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>195</td>\n",
       "      <td>10</td>\n",
       "      <td>195_deconstruction_dictionary_derrida_dictionaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "      <td>196_apple_apples_jobs_newton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>197</td>\n",
       "      <td>10</td>\n",
       "      <td>197_henry_henrys_england_elizabeth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                                Name\n",
       "0   -1      2905   -1_the_of_to_in                                   \n",
       "1    0      280    0_american_politician_english_author              \n",
       "2    1      229    1_film_he_his_films                               \n",
       "3    2      224    2_cells_dna_cell_acid                             \n",
       "4    3      200    3_species_are_have_their                          \n",
       "..  ..      ...                         ...                          \n",
       "194  193    10     193_french_lit_france_fries                       \n",
       "195  194    10     194_nietzsche_wittgenstein_marx_hegel             \n",
       "196  195    10     195_deconstruction_dictionary_derrida_dictionaries\n",
       "197  196    10     196_apple_apples_jobs_newton                      \n",
       "198  197    10     197_henry_henrys_england_elizabeth                \n",
       "\n",
       "[199 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_gpu_0.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c69e9a24-fea9-4aa8-8f39-d1c5c2f98fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('american', 0.03824015490601593),\n",
       " ('politician', 0.02487952246074146),\n",
       " ('english', 0.01868566576677697),\n",
       " ('author', 0.016188505725766307),\n",
       " ('player', 0.014890340803210339),\n",
       " ('actor', 0.014639880907234854),\n",
       " ('singersongwriter', 0.012203505630253646),\n",
       " ('academic', 0.011779174866669361),\n",
       " ('french', 0.010893248793413838),\n",
       " ('lawyer', 0.010666407025107495)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model_gpu_0.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c188c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_gpu_1.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_gpu_1..get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17748a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from cuml.cluster import HDBSCAN as HDBSCAN_gpu\n",
    "from cuml.manifold import UMAP as UMAP_gpu\n",
    "from cuml.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    globals()[\"start_time_\" + str(i)] = time.time()\n",
    "    globals()[\"umap_model_\" + str(i)] = UMAP_gpu(n_components=5, n_neighbors=15, min_dist=0.0)\n",
    "    globals()[\"hdbscan_model_\" + str(i)] = HDBSCAN_gpu(min_samples=10, gen_min_span_tree=True)\n",
    "    # Pass the above models to be used in BERTopic\n",
    "    globals()[\"topic_model_cubert_\" + str(i)] = BERTopic(umap_model=globals()[\"umap_model_\" + str(i)], hdbscan_model=globals()[\"hdbscan_model_\" + str(i)])\n",
    "    globals()[\"topics_\" + str(i)], globals()[\"probs_\" + str(i)] = globals()[\"topic_model_cubert_\" + str(i)].fit_transform(globals()[\"data_\" + str(i)])\n",
    "    globals()[\"end_time_\" + str(i)] = time.time() - globals()[\"start_time_\" + str(i)]\n",
    "    print(\"Time to perform topic modeling for dataset\" +str(i+1) + \"(in s): \"+ str(np.round(globals()[\"end_time_\" + str(i)], decimals=2)))\n",
    "    \n",
    "    viz_topics = globals()[\"topic_model_cubert_\" + str(i)].visualize_topics()\n",
    "    # print(viz_topics.show())\n",
    "    viz_topics.write_html(\"viz_topics_cu_\"+str(i)+\".html\")\n",
    "    viz_barchart = globals()[\"topic_model_cubert_\" + str(i)].visualize_barchart()\n",
    "    # print(viz_barchart.show())\n",
    "    viz_barchart.write_html(\"viz_barchart_cu_\"+str(i)+\".html\")\n",
    "    # viz_docs = globals()[\"topic_model_cubert_\" + str(i)].visualize_documents(globals()[\"data_\" + str(i)])\n",
    "    # viz_docs.write_html(\"viz_docs_\"+str(i)+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_cubert_0.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb76f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_cubert_0.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a67520",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_cubert_1.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_cubert_1.get_topic(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23aff4-7ed1-4f16-989e-72522b4989cb",
   "metadata": {},
   "source": [
    "### Running customized BERTopic without CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee27bc6-3036-48a9-abfd-394f5842e2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 2s, sys: 5.78 s, total: 2min 8s\n",
      "Wall time: 46.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Customizing HDBSCAN \n",
    "hdbscan_model_1 = HDBSCAN(min_cluster_size=10, metric='euclidean', \n",
    "                        cluster_selection_method='eom', prediction_data=True, min_samples=5)\n",
    "topic_model_1 = BERTopic(hdbscan_model=hdbscan_model_1)\n",
    "topics_cpu_1, probs_cpu_1 = topic_model_1.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b95030-7ed1-4943-89b4-f584fbc6aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c484245e-3fcd-41b0-80b1-e1a18e1f1c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min, sys: 5.59 s, total: 2min 6s\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Customizing embedding \n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
    "topic_model_2 = BERTopic()\n",
    "topics_cpu_2, probs_cpu_2 = topic_model_2.fit_transform(docs, embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
